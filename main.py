#  Copyright (c) 2024 by Tomoya Konishi
#  All rights reserved.
#
#  License:
#  This program is permitted under the principle of "NO WARRANTY" and
#  "NO RESPONSIBILITY". The author shall not be liable for any event
#  arising in any way out of the use of these resources.
#
#  Redistribution in source and binary forms, with or without
#  modification, is also permitted provided that the above copyright
#  notice, disclaimer and this condition are retained.
#
#
#

import streamlit as st
import numpy as np
import pandas as pd
import fitz
import cv2
import imutils
from imutils.perspective import four_point_transform
import re
import base64

import const
import my_img

# å‚è€ƒ
# https://qiita.com/not13/items/dcd8c12d64982dc0e819

def main():
    # UIã®æ§‹ç¯‰
    st.markdown(const.STYLE, unsafe_allow_html=True)
    st.title('OMR2 - ãƒãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆãƒªãƒ¼ãƒ€ãƒ¼')

    st.sidebar.write("""
    ## â— ãƒãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆ
    """)
    file_path = st.sidebar.file_uploader("PDFãƒ•ã‚¡ã‚¤ãƒ«", type="pdf")

    if not file_path:
        # st.sidebar.write("ãƒãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")
        st.info("ãƒãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„", icon="â„¹ï¸")
        return
    else:
        try:
            if st.session_state.file_path != file_path:
                st.cache_data.clear()
        except AttributeError:
            pass

        st.session_state.file_path = file_path

        pdf_document = fitz.open(stream=file_path.read(), filetype="pdf")
        if pdf_document.page_count > 1:
            page = st.sidebar.slider('ãƒšãƒ¼ã‚¸é¸æŠ [â†] [â†’]', 1, pdf_document.page_count, 1)
        else:
            page = 1

        img_width = st.sidebar.slider('è¡¨ç¤ºã‚µã‚¤ã‚º', 0, 1000, 500, step=10)

    st.sidebar.write("""
    ## â— ãƒãƒ¼ã‚¯æ¤œå‡ºè¨­å®š
    """)
    if st.sidebar.checkbox('ç”»åƒ2å€¤åŒ–é–¾å€¤ã®è‡ªå‹•è¨­å®š', value=True):
        threshold = 0
    else:
        threshold = st.sidebar.slider('', 0, 255, 170)

    if st.sidebar.checkbox('å°ã•ã„ãƒãƒ¼ã‚¯ã‚’è‡ªå‹•ã§é™¤å¤–', value=True):
        acceptable_small_size = 0.4
    else:
        acceptable_small_size = st.sidebar.slider('', 0.0, 1.0, 0.4, step=0.05)

    is_double_mark = st.sidebar.checkbox('ãƒ€ãƒ–ãƒ«ãƒãƒ¼ã‚¯ã‚’è¨±å¯', value=True)
    str_dimensions = st.sidebar.text_input('å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒãƒ¼ã‚¯æ•°(è¡Œxåˆ—)', value='(4x10), (30x10), (30x10)')
    # ã‚¿ãƒ—ãƒ«ã®ãƒªã‚¹ãƒˆã«å¤‰æ›
    matches = re.findall(r'\((\d+)[x,](\d+)\)', str_dimensions)
    dim_list = [(int(x), int(y)) for x, y in matches]

    # å‡¦ç†é–‹å§‹
    download_button = st.sidebar.button("å…¨ã¦ã®ã‚·ãƒ¼ãƒˆã‚’ä¸€æ‹¬å‡¦ç† ğŸš€")

    if download_button:
        data_list, image_list = do_all_omr(pdf_document, threshold, acceptable_small_size, is_double_mark, dim_list)

        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
        csv = pd.DataFrame(data_list).to_csv(index=False)
        csv_b64 = base64.b64encode(csv.encode()).decode()

        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
        pdf_doc = fitz.open()
        for image in image_list:
            _, jpg_buf = cv2.imencode(".jpg", image, (cv2.IMWRITE_JPEG_QUALITY, 50))
            page = pdf_doc.new_page()
            page.insert_image(page.rect, stream=jpg_buf.tobytes())
        pdf_b64 = base64.b64encode(pdf_doc.tobytes()).decode()

        st.balloons()
        st.success("å…¨ã¦ã®ã‚·ãƒ¼ãƒˆã®èª­ã¿å–ã‚ŠãŒå®Œäº†ã—ã¾ã—ãŸ", icon="âœ…")
        st.markdown(const.RESULTS.format(csv_b64=csv_b64, pdf_b64=pdf_b64), unsafe_allow_html=True)

        st.button('æˆ»ã‚‹')
    else:
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        table, img = do_omr(pdf_document, page, threshold, acceptable_small_size, is_double_mark, dim_list)

        # åŠ å·¥æ¸ˆã¿ç”»åƒã®è¡¨ç¤º
        st.write("### ãƒãƒ¼ã‚¯æ¤œå‡ºçµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.image(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), width=img_width)

        # çµæœã®è¡¨ç¤º
        st.write("### ãƒãƒ¼ã‚¯èª­ã¿å–ã‚Šçµæœ")
        df = pd.DataFrame(table,
                          index=(range(1, len(dim_list)+1)),
                          columns=(range(1, max(dim_list)[0]+1)))
        st.table(df)


@st.cache_data
def do_all_omr(_pdf_document, threshold, acceptable_small_size, is_double_mark, dim_list):
    data_list = []
    image_list = []
    for page in range(1, _pdf_document.page_count+1):
        table_list, image = do_omr(_pdf_document, page, threshold, acceptable_small_size, is_double_mark, dim_list)
        # 1æ¬¡å…ƒãƒªã‚¹ãƒˆã«å¤‰æ›
        table_list = [item for sublist in table_list for item in sublist]
        data_list.append(table_list)
        image_list.append(image)

    return data_list, image_list


@st.cache_data
def do_omr(_pdf_document, page, threshold, acceptable_small_size, is_double_mark, dim_list):
    # å‡¦ç†é–‹å§‹
    table_list = []
    img = get_image_from_pdf(_pdf_document, page)
    img = correct_tilt(img)
    frame_list = find_frames(img)

    if len(frame_list) == 0:
        st.error("ã‚¨ãƒ©ãƒ¼ï¼ è§£ç­”æ ãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚", icon="âŒ")
        st.stop()

    for i, frame in enumerate(frame_list):
        mark_list, frame_img = find_marks(img, frame, threshold, acceptable_small_size)

        try:
            _ = dim_list[i]
        except IndexError:
            st.error("è§£ç­”æ ã®å€‹æ•°({})ã«å¯¾ã—ã¦ãƒãƒ¼ã‚¯æ•°è¨­å®š(nxm)ã®æ•°({})ãŒä¸è¶³ã—ã¦ã„ã¾ã™"
                       .format(len(frame_list), len(dim_list)), icon="âŒ")
            st.stop()

        frame_width = np.max(frame[:,0]) - np.min(frame[:,0])
        frame_height = np.max(frame[:,1]) - np.min(frame[:,1])
        data = decode_marks((frame_height, frame_width), mark_list, dim_list[i], is_double_mark)
        table_list.append(data)

        # æ¤œå‡ºã—ãŸãƒãƒ¼ã‚¯ã®æç”»
        frame_origin = (np.min(frame[:,0]), np.min(frame[:,1]))
        for mark in mark_list:
            for pt in mark:
                pt[0] += frame_origin

            cv2.drawContours(img, [mark], -1, (0, 0, 255), 2)

    # è§£ç­”æ ã®æç”»
    for i,c in enumerate(frame_list):
        cv2.drawContours(img, [c], 0, (0, 255, 0), 2)
        cv2.putText(img, str(i), (np.min(c[:,0]), np.min(c[:,1])-20), cv2.FONT_HERSHEY_SIMPLEX,
                    1, (0, 255, 0), 2)
        # cv2.circle(img, (np.min(c[0,0]), np.min(c[0,1])), 5, (255, 0, 0), -1)
        # cv2.circle(img, (np.min(c[1,0]), np.min(c[1,1])), 5, (0, 255, 0), -1)
        # cv2.circle(img, (np.min(c[2,0]), np.min(c[2,1])), 5, (0, 0, 255), -1)

    return table_list, img


def get_image_from_pdf(pdf_document, page):
    """
    PDFãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æŒ‡å®šã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã‹ã‚‰ç”»åƒã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚

    Args:
        pdf_document (fitz.Document): PDFãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚
        page (int): èª­ã¿è¾¼ã‚€ãƒšãƒ¼ã‚¸ç•ªå·ï¼ˆ1ã‹ã‚‰å§‹ã¾ã‚‹ï¼‰ã€‚

    Returns:
        numpy.ndarray: èª­ã¿è¾¼ã¾ã‚ŒãŸç”»åƒã€‚
    """

    # https://note.com/jolly_ixia1223/n/n499b3480fedc
    # https://qiita.com/inoshun/items/ded26487bf0065794d2c

    pdf_page = pdf_document[page-1]
    image_list = pdf_page.get_images(full=True)
    image_index = image_list[0][0]
    base_image = pdf_document.extract_image(image_index)
    image_bytes = base_image["image"]
    image_np = np.frombuffer(image_bytes, np.uint8)
    img = cv2.imdecode(image_np, cv2.IMREAD_COLOR)

    rotation = pdf_page.rotation
    if rotation == 90:
        img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)
    elif rotation == 180:
        img = cv2.rotate(img, cv2.ROTATE_180)
    elif rotation == 270:
        img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)

    margin_w, margin_h = img.shape[1]*0.05, img.shape[0]*0.03
    img = img[int(margin_h):int(-margin_h), int(margin_w):int(-margin_w)]

    if my_img.is_binary_image(img):
        st.warning("2å€¤åŒ–ã•ã‚ŒãŸç”»åƒã§ã™ã€‚ãªã‚‹ã¹ãã‚«ãƒ©ãƒ¼ã§èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚", icon="âš ï¸")

    elif my_img.is_gray_image(img):
        st.warning("ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒã§ã™ã€‚ãªã‚‹ã¹ãã‚«ãƒ©ãƒ¼ã§èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚", icon="âš ï¸")
        # st.warning("ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ç”»åƒã§ã™ã€‚ãªã‚‹ã¹ãã‚«ãƒ©ãƒ¼ã§èª­ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚", icon=":material/warning:")

    # elif my_img.is_color_image(img):
    #    st.write("ã‚«ãƒ©ãƒ¼ç”»åƒã§ã™ã€‚")

    width = 2000
    img = cv2.resize(img, (int(img.shape[1]*width/img.shape[0]), width))

    return img


def correct_tilt(img):
    ### ç”»åƒã®å‚¾ãè£œæ­£
    # https://note.com/bibinbeef/n/ne399c766d9d5
    frame_list = find_frames(img)
    if len(frame_list) > 0:
        max_frame = sorted(frame_list, key=cv2.contourArea, reverse=True)[0]
        vec = max_frame[1] - max_frame[0]
        rot_theta = np.arctan2(vec[0], vec[1]) *180/3.14
        img = imutils.rotate(img, -rot_theta)
    return img



def threshold_image(image, threshold):
    """
    ç”»åƒã®2å€¤åŒ–
    :param image:
    :param threshold: è‡ªå‹•è¨­å®šã®å ´åˆã¯0
    :return:
    """
    img = cv2.GaussianBlur(image,(5,5),0)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    if threshold == 0:
        threshold_type = cv2.THRESH_OTSU
    else:
        threshold_type = cv2.THRESH_BINARY
    _, img = cv2.threshold(img, threshold, 255, threshold_type)
    return 255 - img


def find_frames(img):
    ### ãƒ•ãƒ¬ãƒ¼ãƒ (ãƒãƒ¼ã‚¯é ˜åŸŸ)ã®æ¤œå‡º

    # img = cv2.blur(img, (5, 5))

    # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    # img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel, iterations=5)

    ksize = 1
    img = cv2.medianBlur(img, ksize)

    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = cv2.GaussianBlur(img, (5, 5), 5)
    edged = imutils.auto_canny(img)

    frame_contours = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    frame_contours = imutils.grab_contours(frame_contours)
    cnt_list = []

    if len(frame_contours) > 0:
        for c in frame_contours:
            # å°ã•ã„é ˜åŸŸã¯ç„¡è¦–
            if cv2.contourArea(c) < img.shape[0]*img.shape[1]*0.02:
                continue

            peri = cv2.arcLength(c, True)
            approx = cv2.approxPolyDP(c, 0.02 * peri, True)
            if len(approx) == 4:
                # sort the approx points starting from the top-left
                # xåº§æ¨™ã¨yåº§æ¨™ã®å’ŒãŒæœ€å°ã®ç‚¹ã‚’å·¦ä¸Šã«ã™ã‚‹
                w = [i[0][0]+i[0][1] for i in approx]
                idx = w.index(min(w))
                idx_list = list(range(len(w)))
                idx_list = idx_list[idx:] + idx_list[:idx]
                approx = approx[idx_list]
                cnt_list.append(approx.reshape(4, 2))

    cnt_list = sorted(cnt_list, key=lambda x: (np.mean(x[:]), np.mean(x[:0])))
    return cnt_list


@st.cache_data
def find_marks(image, frame, threshold, acceptable_small_size = 0.4):
    """
    ã—ãã„å€¤å‡¦ç†ã¨ãƒã‚¤ã‚ºé™¤å»ã‚’è¡Œã£ãŸå¾Œã€ç”»åƒã®æŒ‡å®šã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ å†…ã®ãƒãƒ¼ã‚¯ã‚’æ¤œå‡ºã—ã¾ã™ã€‚

    Args:
        image (numpy.ndarray): å…¥åŠ›ç”»åƒã€‚
        frame (numpy.ndarray): ç”»åƒå†…ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®åº§æ¨™ã€‚
        threshold (int): 2å€¤åŒ–ã®ãŸã‚ã®ã—ãã„å€¤ã€‚0ã®å ´åˆã¯å¤§æ´¥ã®æ–¹æ³•ã‚’ä½¿ç”¨ã€‚
        acceptable_small_size (float): ãƒãƒ¼ã‚¯ã¨ã—ã¦èªè­˜ã™ã‚‹æœ€å°ã®ã‚µã‚¤ã‚ºã€‚

    Returns:
        tuple: ä»¥ä¸‹ã‚’å«ã‚€ã‚¿ãƒ—ãƒ«:
            - list: æ¤œå‡ºã•ã‚ŒãŸãƒãƒ¼ã‚¯ã‚’è¡¨ã™è¼ªéƒ­ã®ãƒªã‚¹ãƒˆã€‚
            - numpy.ndarray: å‡¦ç†ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã€‚
    """
    warped_img = imutils.perspective.four_point_transform(image, frame)
    bin_img = threshold_image(warped_img, threshold)
    bin_img = my_img.remove_lines(bin_img)

    # åç¸®ãƒ»è†¨å¼µã«ã‚ˆã‚Šãƒã‚¤ã‚ºã‚’é™¤å»
    kernel = np.ones((3, 3), np.uint8)
    bin_img = cv2.erode(bin_img, kernel, iterations=2)
    bin_img = cv2.dilate(bin_img, kernel, iterations=2)

    # ãƒãƒ¼ã‚¯ã®æ¤œå‡º
    mark_contours = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    mark_contours = imutils.grab_contours(mark_contours)
    if len(mark_contours) == 0:
        return [], warped_img

    # ç·šçŠ¶ã®é ˜åŸŸã‚’å‰Šé™¤
    results = []
    for c in mark_contours:
        (x, y, w, h) = cv2.boundingRect(c)
        ar = w / float(h)
        if 0.5 < ar < 2:
            results.append(c)
    mark_contours = results

    # acceptable_small_sizeã‚ˆã‚Šå°ã•ã„ãƒãƒ¼ã‚¯ã‚’å‰Šé™¤
    max_area = np.max([cv2.contourArea(c) for c in mark_contours])
    mark_contours = [c for c in mark_contours
                     if cv2.contourArea(c) > max_area * acceptable_small_size]

    # ãƒãƒ¼ã‚¯ã®ä¸¦ã³æ›¿ãˆï¼ˆå·¦ä¸Šã‹ã‚‰å³ä¸‹ã¸ï¼‰
    mark_contours = sorted(mark_contours, key=lambda arg: (np.mean(arg[:]), np.mean(arg[:0])))
    return mark_contours, warped_img


def decode_marks(frame_dim, mark_list, mark_array_dim, is_double_mark):
    """
    æŒ‡å®šã•ã‚ŒãŸè§£ç­”æ¬„ã®å¯¸æ³•ã¨ãƒãƒ¼ã‚¯ãƒªã‚¹ãƒˆã«åŸºã¥ã„ã¦ãƒãƒ¼ã‚¯ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã€‚

    Args:
        frame_dim (tuple): è§£ç­”æ¬„ã®å¯¸æ³• (é«˜ã•, å¹…)ã€‚
        mark_list (list): æ¤œå‡ºã•ã‚ŒãŸãƒãƒ¼ã‚¯ã®ãƒªã‚¹ãƒˆã€ãã‚Œãã‚Œã®ãƒãƒ¼ã‚¯ã¯ãã®é‡å¿ƒã§è¡¨ã•ã‚Œã‚‹ã€‚
        mark_array_dim (tuple): ãƒãƒ¼ã‚¯é…åˆ—ã®å¯¸æ³• (è¡Œ, åˆ—)ã€‚
        is_double_mark (bool): ãƒ€ãƒ–ãƒ«ãƒãƒ¼ã‚¯ã‚’è¨±å¯ã™ã‚‹ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°ã€‚

    Returns:
        list: å„è¡Œã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒãƒ¼ã‚¯æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆã€‚ãƒ€ãƒ–ãƒ«ãƒãƒ¼ã‚¯ãŒè¨±å¯ã•ã‚Œã¦ã„ãªã„å ´åˆã€
              è¤‡æ•°ã®ãƒãƒ¼ã‚¯ãŒã‚ã‚‹è¡Œã¯ 'X' ã§ãƒãƒ¼ã‚¯ã•ã‚Œã¾ã™ã€‚
    """

    mark_index = {char: index for index, char in enumerate(const.MARK)}

    frame_height, frame_width = frame_dim
    mark_rows, mark_cols = mark_array_dim

    data_list = [""] * mark_rows

    mark_centroid_list = [np.mean(mark, axis=0)[0] for mark in mark_list]
    mark_centroid_list = sorted(mark_centroid_list, key=lambda arg: arg[1])
    for mark in mark_centroid_list:
        x, y = mark
        # ãƒãƒ¼ã‚¯ãŒã©ã®ã‚»ãƒ«ã«å±ã™ã‚‹ã‹
        row = int((y/frame_height)*mark_rows)
        col = int((x/frame_width)*mark_cols)
        if is_double_mark:
            # ãƒ€ãƒ–ãƒ«ãƒãƒ¼ã‚¯ã‚’è¨±å¯
            data_list[row] += const.MARK[col]
        else:
            if data_list[row] == "":
                data_list[row] = const.MARK[col]
            else:
                data_list[row] = "X"

    # ãƒãƒ¼ã‚¯ç•ªå·ã®ä¸¦ã³æ›¿ãˆ("X"ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã®ã¾ã¾)
    return ["X" if "X" in data else ''.join(sorted(data, key=lambda arg: mark_index[arg]))
            for data in data_list]


if __name__ == "__main__":
    main()